\documentclass{mitschrift}

% Includes
\usepackage{natbib}
\usepackage[toc]{glossaries}

% Newcommands
\newcommand{\pje}{\marginpar{Philipp\\Jeske}}
\newcommand{\bmn}{\marginpar{Benjamin\\Morgan}}

\makeglossaries

%opening
\titlehead{Management im Software Engineering \\ Universität Würzburg \\ WS 2013/2014}
\title{Test Driven Development}
\subject{Ausarbeitung}
\author{Philipp Jeske \and Benjamin Morgan}
\date{\today}

% Glossar
\newglossaryentry{xtremeProgramming}{
  name={Extreme Programming},
  description={Agiles Softwareentwicklungsparadigma}
}
\newacronym{xp}{XP}{\gls{xtremeProgramming}}

\newglossaryentry{prodCode}{
  name={Production Code},
  description={Quelltext, der in das finale Produkt eingebaut wird}
}

\newglossaryentry{ideLang}{
  name={Integrated Development Environment},
  description={Bezeichnet einen speziell für die Softwareentwicklung gebauten Texteditor, der häufig auf eine Sprache spezialisiert ist und für diese bereits Compiler und Debugger mitliefert.}
}
\newacronym{ide}{IDE}{\gls{ideLang}}

\newglossaryentry{tesDrDev}{
  name={Testgetriebene Entwicklung},
  description={häufig auch testdriven development}
}
\newacronym{tdd}{TDD}{\gls{tesDrDev}}

\begin{document}

\maketitle

\tableofcontents

\begin{abstract}
 Diese Ausarbeitung wurde im Rahmen der Vorlesung "`Management im Software
 Engineering"' an der Universität Würzburg im Wintersemester 2013/2014 bei Dr.
 Jürgen Schmied geschrieben. Im Folgenden wird ein kurzer Überblick über das
 Entwicklungsparadigma "`Testgetriebene Entwicklung"' gegeben und anhand eines
 Beispieles die wichtigsten Faktor aufgezeigt. Anschließend werden Vor- und
 Nachteile aufgezeigt und ein Fazit gezogen. Abschließend steht noch ein
 persönlicher Erfahrungsbericht der beiden Autoren dieser Arbeit.
\end{abstract}

\chapter{Einführung}
\pje
Bei den klassischen Entwicklungsmodellen werden Tests erst nach Fertigstellung
einzelner Module ausgeführt, dies führt dazu, dass unter Umstände vielen
Nacharbeiten nötig sind bevor mit dem nächsten Modul angefangen werden kann.
Auch ist es bei diesem Vorgehen möglich, dass Funktionen vergessen werden zu
implementieren. Dieses Problem ist gerade heutzutage immer schwer wiegender, da
die Software immer komplexer wird und somit die Pflichtenhefte immer länger
werden. Im Zusammenspiel mit Zeitdruck im Projekt führt dies dazu, dass manches
überlesen werden kann. Eine weitere Problematik die bei klassischen Methoden
auftreten kann, ist dass Tests vernachlässigt werden, sollte es am Projektende
eng werden oder der Kostenrahmen gesprengt werden.

Diese Probleme versucht die agile Softwareentwicklungs-Methode \gls{xp} mit
häufigen Testen und Pair Programming zu umgehen. Mittlerweile hat sich der
Aspekt des häufigen Testens zu einem eigenen Paradigma entwickelt und findet in
vielen Bereichen Anwendung in den hohe Codequalität gefordert wird. Bei
\gls{tdd} steht das regelmäßige Testens seines Codes bereits in während der
Implementierung im Mittelpunkt. Da dazu die Test bereits vor dem \gls{prodCode}
geschrieben werden, wird auch teilweise bereits auf Vollständigkeit geprüft. Im
folgenden Kapitel wird auf die genaue Definition von Testgetriebener
Entwicklung genauer eingegangen.

\chapter{Definition}
\bmn

Uncle Bob's Three Laws of TDD \cite{UncleBob}
--------------------------------------

 1. You are not allowed to write any production code unless it is to make
    a failing unit test pass.
 2. You are not allowed to write any more of a unit test than is sufficient
    to fail; and compilation failures are failures.
 3. You are not allowed to write any more production code than is sufficient
    to pass the one fialing unit test.
 4. You are not allowed to write untestable code (user comment).

In a sense, a developer only responds to failing tests.

It follows that

 - you can't spend much time writing *only* tests or *only* code,
 - the system is constantly in a cycle of compiling and executing,
 - you need tooling that supports this (often closely related to the
   language itself; i.e. C or C++ make this difficult.)

The goal of all this is to have code that is almost always working – you
don't need to waste time debugging.

Summary
-------

TDD is only a part of the Agile development technique. It consists of *test
first development* (TFD) and *refactoring*. This turns traditional
development around, which normally ends with the testing, rather than
beginning with it.

Some call it a agile requirements and design technique, others see it more
as a programming technique. Both may be correct, as it depends on how far
you take TDD.

TDD is a short iterative development cycle.

### Methods

 1. Think about what you want to do.
 2. Think about how to test it.
 3. Think about the desired API.
 5. Write just enough test code to make it fail. Watch it fail.
 6. Write just enough functional code to make it pass the test.
 7. Refactor, deduplicate, make more efficient, etc.
 8. Run the test suite. If it passes, go to 1, else continue.
 9. Try to fix the introduced problem, or revert, then go to 8.

### Side Effects

 - You are probably going to have more LOC for tests than for the functional
   code. \cite{SQlite} \cite{C2}
 - TDD causes you to write interface heavy code; this can be a good thing,
   but for small projects it might be excessive.

\chapter{Umsetzung}
\pje
Die Umsetzung der \gls{tdd} erfolgt in mehren Stufen und findet auf
unterschiedlichen Integrationsebenen statt. Je nach Ebene werden
unterschiedliche Praktiken und Tools angewendet, auf die im Folgenden näher
eingegangen wird.

\section{Unit-Tests}
Die bekannteste Testtechnik in der Softwareentwicklung sind wahrscheinlich die
\textsc{Unit}- bzw. Modultests. Diese werden häufig mit Hilfe von in die
Entwicklungssprache und die \gls{ide} integrierte Testframeworks durchgeführt.
Einer der bekanntesten und ersten Repräsentanten dieser Testframeworks ist
jUnit. Mittlerweile gibt es viele Ports auf andere Sprachen und Platformen, zum
Beispiel nUnit für das .NET-Framwork von Microsoft oder cUnit für C und C++,
das nicht nur auf x86- und x64-Platformen portiert wurde, sondern unter anderem
auch auf MIPS und MSP430.

Diese Test finden auf der untersten Ebene statt und sichern die Software gegen
Implementierungsfehler von Teilaufgaben ab, so werde einzelne Funktionen auf
die korrekte Ausgabe bei einer genau definierten Eingabe getestet. Auf dieser
Integrationsebene werden alle Objekte, die mit dem zu testenden Objekt
interagieren durch so genannte Mock-Objekte abstrahiert.

Ein Mock-Objekt bietet die gleiche Schnittstellen wie das zu simulierende
Objekt, allerdings sind die Ausgaben fest definiert, um ein deterministischen
Verhalten ohne Interferenzen mit unter Umständen externen Quellen zu vermeiden.
Zum Beispiel wird bei datenverarbeitenden Programmen der Datenbankzugriff auf
ein Mock-Objekt zum Testen abgebildet, da dadurch sich die Eingabe genau
definieren lässt.

Die Unit-Tests werden bei Anwendung des Paradigmas der \gls{tdd} bei jeder
kleinsten Änderung ausgeführt und die Entwicklung wird erst durchgeführt,
sobald der entsprechende Test fehlerfrei durchläuft.

\section{Integrationtests}
Bei den Integrationstests, die häufig auch noch mit den Testframeworks
durchgeführt werden, werden in einzelnen Iterationen die Mock-Objekte durch ihr
reales Pendant ersetzt und dadurch kontrolliert, dass die Zusammenarbeit der
Komponenten untereinander fehlerfrei funktioniert.

Die Integrationstests werden bei der \gls{tdd} ab der ersten Iteration ständig
durchgeführt ab der eine Integration möglich ist. Beim Beispiel der
datenverarbeitenden Anwendung, wird neben den Modultests, die z.B. die
Berechnung eines Indexes usw. beinhalten, ab der vollständigen Implementierung
des Datenbankzugriffes neben dem Mock-Objekt-Test auch direkt der
Datenbankzugriff getestet, um frühzeitig Probleme bzw. Fehler zu erkennen und
diese in einem frühen Stadium beheben zu können.

\section{Systemtest}
Sind alle Teile einer Anwendung erfolreich mit Modultests und Integrationstests
getestet, kann die letzte Iteration der Integrationstests durchgeführt werden.
Diese wird auch häufig als Systemtest bezeichnet und ist der erste Test, bei
dem alle Komponenten zusammenspielen und ihr Verhalten miteinander getestet
wird.

Ab der ersten vollständigen Integration aller Komponenten wird bei der jeder
Iteration des Refactor/Debug-Zyklus neben Unit-Tests und den Integrationstests
ausgeführt auch bei diesem Test gilt, die Entwicklung wird erst fortgesetzt,
wenn alle Tests erneut erfolreich bestanden sind.

\chapter{Vorraussetzungen}
\bmn
In order for TDD to really make sense, all the following points must hold.

 - You are writing code that is testable in a unit-test manner. \[[4][4]\]
 - That what you are developing has an obvious approach and will not require
   extensive prototyping or experimentation. \[[4][4]\]
 - That you will not need to refactor too heavily or change the
   specification unless you have the time to repeatedly rewrite hundreds
   or thousands of test cases. \[[4][4]\]
 - Nothing is sealed. \[[4][4]\]
 - Everything is modular. \[[4][4]\]
 - Everything is injectable or mockable. \[[4][4]\]
 - That there is something of benefit to test at a unit test level. \[[4][4]\]
 - The management and the development team must accept and apply TDD
   thoroughly. \[[4][4]\]
 - That your organization places a high enough value on low-defects to
   justify the resource sink \[[4][4]\]


\chapter{Beispiel}
\pje

\chapter{Vorteile}
\bmn

 - a creation of hundreds and thousands of tests, which can be run at any
   time, because they all should be passing;
 - transparency in the code;
 - tests that act as documentation and code examples, they are always
   up-to-date;
 - the tests make up the specification, this is unambiguous and also
   requires you to think through the specification before you start writing
   any code;
 - a testable design and code base, because the TDD technique forces the
   design to be testable;
 - the ability to refactor at will, because the tests cover all the code
   paths and functions;
 - no fear of touching the code or deleting code, the code becomes malleable
 (again) and makes it a lot *softer* again; \cite{UncleBob}
 - TDD forces the design to be testable, and makes future development by
   yourself and others a lot easier;
 - TDD eliminates excuses and short-cuts; you can't be lazy and the
   management cannot force you to skip the testst when you have a finished
   product because it seems to work ok (the predefined use-cases go
   through).

\chapter{Nachteile}
\bmn
The requirements above may also be seen as weaknesses.

 - Certain software modules or projects are less suited to TDD than others,
   for example projects that are focussed around
    * user interfaces,
    * networking,
    * external interaction,
    * etc.
   Also consider the requirements that a project must fulfill to be fully
   compatible with TDD.
 - Converting legacy projects to TDD can involve a huge amount of work
   – there is no guarantee that all code paths are covered or that the tests
   consider all the cases that have been covered in the code.
 - Seeing hundreds or thousands of passing tests can create a sense of false
   security. \[[4][4]\]
 - Even trivially changing or heavily refactoring the functional code can
   involve rewriting hundreds or even thousands of tests. \[[4][4]\] \[[5][5]\]
 - Requires a huge investment in time to *get into it*, thus it also
   requires a lot of discipline. This can be hard to sell to other
   developers. \[[5][5]\]
 - Selling the full TDD package to management can be very hard. For example,
   TDD is best done with pair programming, which many managers cannot
   accept. \[[5][5]\]
 - You lose a lot of (possibly negative) freedom, because TDD is very rigid
   and specifies much of the software development process. This might be
   an advantage, but some certainly won't like it. \[[5][5]\]
 - Applying TDD *does* require an extra time and resources investment. This
   may be worth it, depending on what you are doing, but it still is a big
   investment. \[[5][5]\]
 - TDD can lock the functional code into a certain design as long as tests
   assume a certain API. If the API is not yet certain or clear, or
   prototyping must be done, then TFD will generate extra work. \[[5][5]\]
 - TDD makes tweaking and tuning (like algorithms) much more expensive.
   \[[5][5]\]
 - The entire set of tests must be maintained and debugged. While the tests
   only help make sure the functional code is good, you still are completely
   responsible for the quality of the tests. Many people do not know how to
   properly create tests. \[[5][5]\]
 - The requirement of testable code results in a much more complex design
   than might be necessary for the problem at hand. \[[5][5]\]
 - If you write the tests and the code yourself, the tests might share the
   same blind spot as the code afterwards.
 - There is a possibility of overtesting, which can slow down development
   and even prevent refactoring.

\chapter{Fazit}
\pje

\chapter{Erfahrungsbericht}
Nach dem objektiven Fazit im vorigen Kapitel, werden hier noch die Erfahrungen
der beiden Autoren zusammengefasst und ein persönliches Fazit gezogen.

\section{Benjamin Morgan}
\bmn
Pure TDD seems a little too masochistic for most projects. I think that a
hybrid approach that incorporates a reasonable yet thorough amount of
testing might be better. For example, the technique might step you through
these steps.

 1. Think through the design.
 2. Design a suitable API for your problem. This may be done best by writing
    usage examples for your future functional code. This might be related to
    example driven development.

    The design process might involve writing prototypes or even writing some
    functional code (gasp!)
 3. Write thorough tests for the API. Make sure you think through all
    possible inputs and their should-be outputs.
 4. Write the functional code, but don't lean on the tests, use them as an
    aid, but don't turn off your brain.

These steps can be applied at various levels of detail. It should be
possible to write more tests or more functional code at a time. This reduces
the number of context switches that are forced upon the programmer.

TDD feels like everything is oriented around the test, which I don't like.
I would much rather have very nice functional code than very nice tests.
But that's just my personal opinion. I think that the way that the Go and
D programming languages incorporate testing is very useful.

\section{Philipp Jeske}
\pje
Ich habe bereits in kleineren Projekten als auch in mittelgroßen Projekten,
versucht \gls{tdd} einzusetzen, jedoch gab es einige Probleme. 

So stelle sich heraus, dass der Aufwand bereits bei kleinen Projekten ziemlich
groß ist, wenn man den ganzen Netzwerkstack mocken muss bzw. den Zugriff auf
eine Datenbank. Ebenso stellte sich heraus, dass es eine Menge Mehraufwand
erzeugt, wenn sich Anforderungen ändern, da diese dann auch in den Tests
nachgezogen werden müssen.

Aber es gab nicht nur negative Beispiele, so eignet sich \gls{tdd} meines
Erachtens um logische Fehler bereits während der Implementierung zu erkennen.
Auch zum Testen von projektinternen Abhängigkeiten der Art "`Klasse A erbt von
Klasse C und implementiert Schnittstelle C"' können mit Hilfe von \gls{tdd}
sehr gut getestet werden.

Aufgrund meiner persönlichen Erfahrungen würde ich weder zu \gls{tdd} raten
noch davon ab. Ich würde einen abgespeckten Workflow vorziehen, der den
Testaufwand auf logische Fehler reduziert, die einfach überprüft werden können
und die Integrationstests nur auf einfache Fälle wie oben beschrieben
beschränkt. Für die restlichen Testpunkte bevorzuge ich den klassischen Ansatz,
da sich der Aufwand dadurch reduziert.

Ferner macht es Sinn, die Tests von spezialisierten Teams schreiben zu lassen,
da dadurch das Problem der Whitebox-Tests weiter umgangen wird und nicht jeder
Entwickler tests schreiben will. Ferner spart es Schulungsaufwand.

\bibliographystyle{natdin}
\bibliography{literatur}

\printglossary

\end{document}
